# 🔍 Prompt Injection Detector — Live Demo Walkthrough

This test demonstrates how a lightweight AI application responds to:
1. Normal user input
2. Malicious prompt injection
3. System prompt leakage
4. Pirate-mode instruction takeovers

---

## ✅ Baseline Safe Input

This is a normal message like “Hi there!”. The system behaves safely.

![Normal Hello Response](../images/prompt-detector/normal-response-hi.png)

---

## ⚠️ Malicious Prompt Detected

When we inject dangerous strings like:

