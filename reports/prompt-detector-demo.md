# ğŸ” Prompt Injection Detector â€” Live Demo Walkthrough

This test demonstrates how a lightweight AI application responds to:
1. Normal user input
2. Malicious prompt injection
3. System prompt leakage
4. Pirate-mode instruction takeovers

---

## âœ… Baseline Safe Input

This is a normal message like â€œHi there!â€. The system behaves safely.

![Normal Hello Response](../images/prompt-detector/normal-response-hi.png)

---

## âš ï¸ Malicious Prompt Detected

When we inject dangerous strings like:

